2020-08-29 Discussion with Tushar Sharma
========================================
* Supervised learnining and standard algorithms
* ML is important but we should emphasis on deep learning
* Diverse tasks like small, medium, and large
* Different sample points (e.g., 1000, 5000, 10.000)
* Hyperparameters tuning: there are available libraries that can do that or empirically
* 4-5 ML frameworks


2020-09-03 Discussion with Maria Kechagia
=========================================

RQ1-2: break to two to test the energy and run-time performance separately.
RQ3: which algorithms are more energy efficient for certain tasks
RQ4: Hyperparameters

Selection criteria for ML algorithms:
1) Open Source
2) Active (commint no more than a year)
3) Popularity (GitHub start)
4) Evaluation (related work)
5) Documentation
6) Programming Languages (Python is the popular, therefore, we select only python frameworks, and python version)
7) Working tutorial
8) Evaluate on the same data


Some thoughts (Tushar)
=======================
Scope: 
- The nature of ML standard algorithms (Logistic regression, SVM, etc.) are quite different than deep learning models (CNN and RNN based). For example, ML algorithms are (very) quick to train compared to deep learning models. Shall we seperate them? Maybe two sub-questions in a RQ?

SG@TS: Yes, I believe we could separate them. Also having standard ML and deep learninig could increase the impact of our research.

- Also, just to be clear and explicit - we are comparing frameworks, right? (not algorithms). I mean, we intend to take a few problems and solve each problem using exact same algorithm but with different frameworks.  

SG@TS: Yes, we would like to compare, for example, the performance of X algorithm developed on the selected ML frameworks. However, if possible, we would also like to suggest which algorithm to use in certain cases (e.g., spam filtering) to win more energy and run-time performance. So these are two different ideas.

- There are many aspects that may vary-task, framework, data, hyper-parameters, programming language, hardware. We need to fix some aspects (hardware, prog. lang, and data) and vary other aspects one at a time in each RQ.

SG@TS: Yes we should, otherwise the time to train the models will increase exponentially. Regarding PL I believe we should use Python as it is the most know and popular for ML.
About data we can set a number of different sample by reading related work, no?

Tasks from FSE (Stefanos)
=========================
1) CIFAR10, MNIST, Udacity Self-Driving Car (all of them are image related tasks)
2) [Kaggle kernels](https://www.kaggle.com/kernels) (Each kernel provides a solution code and description for a specific ML task)
3) MNIST, EMNIST, FMNIST, and KMNIST (all of them are image related tasks)
4) CIFAR-10, STL-10, ImageNet (all of them are imag related tasks)
5) CODEnn-Java-Train, GitHub-Android-Train, and StackOverflow-Android-Train ()


Check the internals like string manipulation or used image library to point out why frameowrk are faster
than other
