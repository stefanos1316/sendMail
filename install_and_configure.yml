---
- hosts: localhost
  gather_facts: false

  tasks:
    - name: Update the apt package index
      become: yes
      apt:
        name: "*"
        state: latest
        update_cache: yes
        force_apt_get: yes

    - name: install required modules
      become: true
      become_user: root
      apt:
        name: ['git', 'linux-tools-`uname -r`', 'apt-transport-https', 'ca-certificates', 'wget', 'software-properties-common', 'gnupg2', 'curl']

    - name: enable sudoless invocation for perf
      become: true
      become_user: root
      shell: sh -c echo -1 >/proc/sys/kernel/perf_event_paranoid && sysctl -w kernel.perf_event_paranoid=-1"
      
    - name: add apt signing key from official docker repo
      become: true
      become_user: root  
      apt_key:
        url: https://download.docker.com/linux/debian/gpg
        state: present

    - name: add docker official repository for Debian Buster
      become: true
      become_user: root
      apt_repository:
        repo: deb [arch=amd64] https://download.docker.com/linux/debian buster stable
        state: present

    - name: Index new repo into the cache
      become: yes
      become_user: root
      apt:
        name: "*"
        state: latest
        update_cache: yes
        force_apt_get: yes
  
    - name: actually install docker
      become: yes
      become_user: root
      apt:
        name: "docker-ce"
        state: latest

    - name: clone and install nvidia-docker
      shell: |
        https://github.com/NVIDIA/nvidia-docker.git
        cd nvidia-docker
        make

    - name: clone repo DeepLearningExamples
      shell: git clone https://github.com/NVIDIA/DeepLearningExamples.git

    # Build and configure Transformer-XL (Pytroch)
    - name: download data-set and build docker image for Pytroch's Transformer-XL
      shell: |
        cd Pytorch/LanguageModeling/Transformer-XL
        mkdir data || echo Already exists
        cd data
        wget --continue https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-v1.zip
        unzip -q wikitext-103-v1.zip
        cd wikitext-103
        mv wiki.train.tokens train.txt
        mv wiki.valid.tokens valid.txt
        mv wiki.test.tokens test.txt
        cd ../..
        rm data/wikitext-103-v1.zip
        bash pytorch/scripts/docker/build.sh

    # Build, configure, and generate train data-set corpuse.json for Transformer-XL (Tensorflow)
    - name: download data-set and build docker image for TensorFlow's Transformer-XL
      shell: |
        cd TensorFlow/LanguageModeling/Transformer-XL
        mkdir data || echo Already exists
        cd data
        wget --continue https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-v1.zip
        unzip -q wikitext-103-v1.zip
        cd wikitext-103
        mv wiki.train.tokens train.txt
        mv wiki.valid.tokens valid.txt
        mv wiki.test.tokens test.txt
        cd ../..
        rm data/wikitext-103-v1.zip
        bash tf/scripts/docker/build.sh
        docker run --gpus all --init -it --rm --network=host --ipc=host -v $PWD:/workspace/transformer-xl transformer-xl bash run_wt103_base.sh train_data